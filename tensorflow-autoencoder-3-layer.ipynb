{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all values between 0 and 1\n",
    "file = r'carbon_nanotubes.csv'\n",
    "df = pd.read_csv(file, delimiter=';', header=None, decimal=',', skiprows=1)\n",
    "x_train = df.drop([0,1], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (10721, 6)\n",
      "No of training examples:  10721\n",
      "No of features:  6\n"
     ]
    }
   ],
   "source": [
    "print('data shape: ', x_train.shape)\n",
    "m = x_train.shape[0]\n",
    "n = x_train.shape[1]\n",
    "print('No of training examples: ', m)\n",
    "print('No of features: ', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batch(X, Y, mini_batch_size = None):\n",
    "    '''xxxxxxxxxxxxxxxxxxxxxxx'''\n",
    "    if mini_batch_size==None:\n",
    "        return print('Need to specify a mini_batch_size.')\n",
    "    else:\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        \n",
    "        mini_batches = []\n",
    "         \n",
    "        # shuffle (X, Y)\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_X = X[permutation, :]\n",
    "        shuffled_Y = Y[permutation, :]#.reshape(m,1) if this was a label vector of shape(m, 1)\n",
    "        \n",
    "        # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "        num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "        for k in range(0, num_complete_minibatches):\n",
    "        \n",
    "            mini_batch_X = shuffled_X[k * mini_batch_size: (k + 1) * mini_batch_size, :]\n",
    "            mini_batch_Y = shuffled_Y[k * mini_batch_size: (k + 1) * mini_batch_size, :]\n",
    "        \n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "        \n",
    "        # Handling the end case (last mini-batch < mini_batch_size)\n",
    "        if m % mini_batch_size != 0:\n",
    "            mini_batch_X =shuffled_X[num_complete_minibatches *mini_batch_size ::, :]\n",
    "            mini_batch_Y =shuffled_Y[num_complete_minibatches *mini_batch_size ::, :]\n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "            \n",
    "        return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "layer1 = 5\n",
    "layer2 = 3\n",
    "layer3 = 5\n",
    "layer4 = n\n",
    "\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer() # This is a He initializtion\n",
    "\n",
    "\n",
    "W1 = tf.get_variable(name='W1', shape=[n, layer1], initializer=initializer)\n",
    "W2 = tf.get_variable(name='W2', shape=[layer1, layer2], initializer=initializer)\n",
    "W3 = tf.get_variable(name='W3', shape=[layer2, layer3], initializer=initializer)\n",
    "W4 = tf.get_variable(name='W4', shape=[layer3, layer4], initializer=initializer)\n",
    "\n",
    "b1 = tf.zeros(shape=[1, layer1], name='b1')\n",
    "b2 = tf.zeros(shape=[1, layer2], name='b2')\n",
    "b3 = tf.zeros(shape=[1, layer3], name='b3')\n",
    "b4 = tf.zeros(shape=[1, layer4], name='b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder(input_placeholder):\n",
    "    '''Create encoder which outputs the latent vector.\n",
    "    \n",
    "    Arguments:\n",
    "    input_placeholder -- tensor, shape[None, m]\n",
    "    \n",
    "    Return:\n",
    "    latent_vector -- tensor, activation of shape[None, layer2]'''\n",
    "    \n",
    "    # linear -> non-linear\n",
    "    Z1 = tf.add(tf.matmul(input_placeholder, W1), b1) # linear\n",
    "    A1 = tf.nn.relu(Z1) # non-linear\n",
    "    \n",
    "    Z2 = tf.add(tf.matmul(A1, W2), b2)\n",
    "    latent_vector = tf.nn.relu(Z2)\n",
    "    \n",
    "    return latent_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoder(latent_tensor):\n",
    "    '''Decode the encoder.\n",
    "    \n",
    "    Arguments:\n",
    "    latent_vec -- tensor, shape[None, layer2]\n",
    "    \n",
    "    Return:\n",
    "    output_layer -- tensor, shape[None, n]'''\n",
    "    Z3 = tf.add(tf.matmul(latent_tensor, W3), b3)\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    \n",
    "    # Use a sigmoid activation our original data is between 0,1\n",
    "    Z4 = tf.add(tf.matmul(A3, W4), b4)\n",
    "    output_layer = tf.nn.sigmoid(Z4)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 has loss of 0.0845633671585336\n",
      "epoch 100 has loss of 0.038846046719924525\n",
      "epoch 200 has loss of 0.037740976044751066\n",
      "epoch 300 has loss of 0.03762571497943745\n",
      "epoch 400 has loss of 0.03752609802387565\n",
      "epoch 500 has loss of 0.037501470758074744\n",
      "epoch 600 has loss of 0.0374481433396598\n",
      "epoch 700 has loss of 0.037366054144250344\n",
      "epoch 800 has loss of 0.03733628555144888\n",
      "epoch 900 has loss of 0.03729753604674915\n",
      "epoch 1000 has loss of 0.037240731339138654\n",
      "epoch 1100 has loss of 0.037207816087876454\n",
      "epoch 1200 has loss of 0.0371243144239647\n",
      "epoch 1300 has loss of 0.037072545366294424\n",
      "epoch 1400 has loss of 0.03698387012693537\n",
      "epoch 1500 has loss of 0.036935740318822574\n",
      "epoch 1600 has loss of 0.036873009100735904\n",
      "epoch 1700 has loss of 0.03681975630033448\n",
      "epoch 1800 has loss of 0.03679333777582072\n",
      "epoch 1900 has loss of 0.036769799641277426\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 2000\n",
    "mini_batch_size = 128\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n], name='input')\n",
    "\n",
    "encoded_out = encoder(X)\n",
    "reconstruction = decoder(encoded_out)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(tf.subtract(X, reconstruction)))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "losses = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):  \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        num_mini_batches = int(m/mini_batch_size)  # No. of mini_batches that have mini_batch size.\n",
    "        \n",
    "        minibatches = random_mini_batch(x_train, x_train, mini_batch_size=mini_batch_size)  # inibatches is a list of tuples.\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "            \n",
    "            (minibatch_X, _) = minibatch\n",
    "            \n",
    "            _, minibatch_loss = sess.run([optimizer, cost], feed_dict={X: minibatch_X})\n",
    "            \n",
    "            epoch_loss += minibatch_loss/num_mini_batches\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            losses.append(epoch_loss)\n",
    "        if epoch % 100 == 0:\n",
    "            print('epoch {} has loss of {}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17d9b402be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline\n",
    "plt.plot(np.arange(0, epochs, 5), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "ax=plt.title('Learing Rate = ' + str(learning_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
